ğŸ§¾ **Customer Loss Data Pipeline (End-to-End DE Project)**

This is a real-world data engineering project built using **Spark SQL on Databricks**. The goal was to design and implement a full data pipeline that simulates how companies manage customer loss, financial risk, and demographic analysis using production-grade data layers.

I built it using the **Medallion architecture**: Bronze â†’ Silver â†’ Silver Validated â†’ Gold.

**ğŸ’¡ What's This Project About?**

Imagine you're working at a utilities or finance company. You have messy customer account data with financial losses, risk flags, and demographic info. You need to clean it, validate it, and deliver solid, trustworthy data to your business teams.

That's what this project does, it transforms raw customer loss data into fully usable BI and risk dashboards, through layered transformations.

**ğŸ§± Architecture Overview (Medallion Style)**

- **Bronze Layer**  
  This is where I land the raw data as-is. No changes, no filters â€” it's like the backup copy.

- **Silver Layer**  
  I cleaned up the data, enforced types, added derived fields (like `IncomeBand`, `AccountAgeDays`), and created detailed validation flags (null checks, date sanity, offset rules).

- **Silver Validated Layer**  
  This is the strict gate. Only rows that pass *all* validation rules are allowed through. I added confidence scores, rejection reasons, row-level hashes, and even DQ metadata. Think of it like: "these rows are safe for business."

- **Gold Layer**  
  This is where the real business value comes out. I created summary tables that show loss trends, segment risk, and income-based behavior that can power dashboards or ML models.

**ğŸ§° Tools & Stack**

- **Databricks**
- **Apache Spark SQL**
- **Unity Catalog (Schema & Governance)**
- **Medallion Architecture**
- **Delta Lake**
- **Data Quality Validation Rules**
- **Dimensional Modeling**
- **Versioning and Metadata Strategy**
- **Git + GitHub**

**ğŸ“ ETL Architecture**
## ğŸ”„ ETL Flow Overview

This project follows a layered ETL approach using the Medallion architecture:

                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                            â”‚   sample_data (.csv)     â”‚
                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   ğŸŸ« Bronze Layer           â”‚
                          â”‚   Raw data: no changes     â”‚
                          â”‚   Table: customer_loss_raw â”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                          â”‚   ğŸ¥ˆ Silver Layer           â”‚
                          â”‚   Typed, cleaned, enriched â”‚
                          â”‚   Table: customer_loss_cleanâ”‚
                          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚
                                         â–¼
               â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
               â”‚     ğŸ§ª Silver Validated Layer                   â”‚
               â”‚     Only high-confidence, valid rows            â”‚
               â”‚     + Flags, rejection reasons, row_hash, etc.  â”‚
               â”‚     Table: customer_loss_strict                 â”‚
               â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â”‚
                            â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                         ğŸŸ¡ Gold Layer                              â”‚
    â”‚   Aggregated business insights for dashboards and reporting:       â”‚
    â”‚   â”œâ”€â”€ loss_summary_by_customer_type                                â”‚
    â”‚   â”œâ”€â”€ loss_summary_by_income_band                                  â”‚
    â”‚   â”œâ”€â”€ monthly_loss_trends                                          â”‚
    â”‚   â””â”€â”€ loss_summary_by_mosaic_group                                 â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


**ğŸ“Š What the Gold Tables Show**

Each Gold table gives a different lens on customer risk and financial loss:

1. **loss_summary_by_customer_type**  
   Shows how much loss is happening by customer type (Person vs Business), including loss rate and risk score.

2. **loss_summary_by_income_band**  
   Breaks down financial loss by income levels. Helps answer: are lower-income customers driving more losses?

3. **monthly_loss_trends**  
   Tracks loss trends over time. Super useful for dashboards or spotting seasonality.

4. **loss_summary_by_mosaic_group**  
   This one's based on demographics (MosaicGroup). It shows which lifestyle segments are riskier financially.

Each one has clear, business-relevant KPIs and a custom `loss_risk_score`.

**ğŸ§ª Data Quality Rules Used**

In the Silver and Silver Validated layers, I used these validation checks:

- **Date sequence check**  
  LossDate can't be before AccountStartDate

- **Offset sanity check**  
  Offset values must be above a threshold

- **Null critical field check**  
  Can't have missing values in fields like `CustomerType`, `OffsetValue`, etc.

- **Demographic null check**  
  Missing Mosaic or income info is flagged separately

These flags were all retained and used to gate data into the strict silver_validated layer.

I also added:
- `validation_status` (Valid / Invalid)
- `rejection_reason` and `rejection_code`
- `row_confidence_score` (a simple quality score per row)
- `row_hash` (for tracking)
- `processed_date`, `schema_version`, `table_version`


**ğŸ“ˆ Business Use Cases This Supports**

- Financial Risk Dashboards
- BI reporting by segment and income
- Monthly loss trend analysis
- Early risk detection and customer targeting
- Future: ML models for loss prediction

**âœï¸ Author**

A data engineer who doesnâ€™t just write SQL â€” I **engineer trust into data**.
If you're into clean architecture, business-aware pipelines, and solving real problems with explainable data... we should talk.
Feel free to reach out if you'd like a walkthrough, feedback, or want to build something exceptional together.



